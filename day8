앙상블
    - 대중적인 데이터 분석 알고리즘
    - 최근 머신러닝/딥러닝 분야에서 딥러닝 다음으로 부스팅 알고리즘이 핵심적으로 사용됨
    - 선형회귀나 로지스틱 회귀는 가장 대중적인 알고리즘이고, 그 다음이 의사결정트리와 앙상블 계열 알고리즘, 딥러닝
    
    앙상블(ensemble)   
        - 여러 개의 알고리즘들이 하나의 값을 예측하는 기법을 통칭하여 말함
        - 회귀 문제에서는 가중평균이나 단순 평균을 구하는 방식으로 Y 값을 예측
        - 메타 분류기라고도 부름
        - 시간이 굉장히 오래 걸리지만 비교적 좋은 성능을 냄
        - 하나의 데이터를 넣음 -> 이를 여러 모델에 학습시키고 -> 테스트 데이터를 각 모델에 입력 -> 투표 또는 여러 가중치 기법을 적용하고 최종 선택

    앙상블 기법들
        바닐라 앙상블
            - 가장 기본적인 앙상블 기법. 바닐라라고하면 아이스크림에서 아무것도 첨가되지 않은 맛인데, 바닐라 앙상블도 아무것도 처리하지 않은 앙상블 모델을 의미
            - 일반적으로 가중치 평균이나 투표 방식으로 만들어지는 앙상블 모델
        
        부스팅
            - 하나의 모델에서 여러 데이터를 샘플링한 다음 그 샘플링된 데이터로 각각의 모델을 만드는 기법
        
        배깅
            - 'boosting aggregation'의 줄임말로 부스팅을 좀 더 발전시킨 기법
            - 하나의 데이터세에서 샘플링을 통해 여러 개의 데이터셋을 만든 다음 각 데이터셋마다 모델을 개발하여 투표 분류기로 만드는 기법
            - 단순하면서 성능이 높아 특히 트리 계열 알고리즘과 함께 많이 사용되며 통계적인 샘플링 기법이나 딥러닝 기법과도 함께 사용
        
        투표 분류기
            - 여러 개의 모델을 만들어 모두 같은 데이터를 넣고 결과를 취합하여 가장 많이 선택된 결과를 취함
            - 앙상블 모델의 가장 기본적인 형태
            - 다수결 분류기라고도 부름
            - 장점 : 다양한 모델을 만든 후, 다음 단계로 매우 쉽게 만들 수 있음
        
        샘플링
            - 다루고자 하는 데이터가 전체 모수라면 그 모수에서 일부분을 뽑아서 데이터를 분석
        
        부트스트래핑
            - 모수 데이터로부터 학습 데이터를 추출할 때 임의의 데이터를 추출한 후 복원추출하는 여러번의 과정
        
        Out-of-bag Error
            - 배깅 모델의 성능을 측정하기 위해서 정확도나 정밀도 외에 사용하는 지표
            - 일반적으로 'OOB error estimation'이라고 부른다
            - 배깅에서 부분집합을 생성할 때 일부 데이터만 학습에 사용되는데, 각 부분집합에서 학습에 사용되지 않은 데이터셋에 대해서만 성능을 측정하여 배깅 모델의 효과를 측정하는 것이다
        
        랜덤 포레스트
            - 하나의 모델을 나무라고 한다면 이러한 나무들을 이용해 랜덤하게 데이터를 뽑아서 숲을 생성하는 알고리즘
        
        배깅과 부스팅의 차이점
            - 병렬화 가능 여부
            - 기준 추정치
            - 성능 차이
        
        병렬화 가능 여부
            - 배깅은 데이터가 n개라면 n개의 CPU로 한번에 처리하도록 구조를 설계할 수 있음
            - 배깅은 데이터를 나눠 데이터마다 조금씩 다른 모델을 생성
            - 부스팅은 단계적으로 모델들을 생성하고 해당 모델들의 성능을 측정한 후 다음 단계로 넘어가 병렬화를 지원하지 않음
            - 부스팅은 배깅에 비해 속도가 매우 떨어짐
        
        기준 추정치
            - 배깅 개별 모델들은 높은 과대적합으로 모델의 분산이 높음
            - 부스팅은 각각의 모델에 편향이 높은 기준 추정치를 사용하여 개별 모델들은 과소적합이 발생하지만 전체적으로 높은 성능을 낼 수 있는 방향으로 학습
            - 부스팅 모델의 이러한 특징을 약한 학습자라고 부름
        
        성능 차이
            - 부스팅은 기본적으로 비용이 높은 알고리즘
            - 배깅은 데이터의 부분집합에 대해 학습을 수행하기 때문에 부스팅보다 좋은 성능을 내기는 어려움
            - 초기 성능을 측정할 때는 배깅, 이후의 성능 측정은 부스팅으로 하는 것이 가장 일반적인 접근

K-평균 군집화
    k-Nearest Neighbor(kNN) 알고리즘
        - 모든 기계 학습 알고리즘 중에서도 가장 간단하고 이해하기 쉬운 분류 알고리즘
    
    군집(clustering)
        - 비슷한 샘플을 클러스터로 모음
        - 비슷한 샘플을 구별해 하나의 클러스터 또는 비슷한 샘플의 그룹으로 할당하는 작업
        - 데이터분석, 고객분류, 이미지분할 등에 사용
    
    이상치 탐지(outlier detection)
        - '정상' 데이터가 어떻게 보이는지를 학습하고, 비정상 샘플을 감지하는데 사용
        - 예를 들면 제조 라인에서 결함 제품을 감지하거나 시계열 데이터에서 새로운 트렌드를 찾는다
    
    밀도 추정(density estimation)
        - 데이터셋 생성 확률 과정의 확률 밀도 함수를 추정한다
        - 밀도 추정은 이상치 탐지에 널리 사용된다
        - 밀도가 매우 낮은 영역에 놓인 샘플이 이상치일 가능성이 높다