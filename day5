머신러닝 딥러닝 기초
    ex1) 인간의 키와 몸무게는 어느 정도 비례할 것으로 예상된다. 아래와 같은 데이터가 있을 때, 선형 회귀를 이용하여 학습시키고 2가지 내용을 표현하시오
        1. 키가 165cm 일 때의 예측값을 얻어 출력
        2. 그래프를 표현하시오
    
    sol) import matplotlib.pylab as plt
         from sklearn import linear_model
         reg = linear_model.LinearRegression()
         X = [[174],[152],[138],[128],[186]]
         y = [71, 55, 46, 38, 88]
         reg.fit(X,y)
         print(reg.predict([[165]]))
         plt.scatter(X,y)
         y_pred = reg.predict(X)
         plt.plot(X, y_pred)
         plt.show()
    
    리지 회귀(ridge regression)
        - L2 정규화
        - 놈
        - 좌표평면의 원점에서 점까지의 거리를 나타내어 벡터의 크기를 측정하는 기법
        - X는 하나의 벡터
        - L2 놈 : 벡터 각 원소들의 제곱합에 제곱근을 취함
    
    라쏘 회귀(lasso regression)
        - L1 정규화라고 부름
        - 가중치에 페널티텀을 추가하는데, 기존 수식에다 L1 놈 페널티를 추가하여 계산
    
    L1 정규화는 직선과 타원 만나는 점이 양쪽 끝에 생성됨
        - 극단적인 값이 생성되어 다른 가중치 값이 선택되지 않는 현상이 발생할 수 있음
        - 사용해야 하는 피쳐와 사용하지 않아도 되는 피쳐를 선택하여 사용하도록 지원
    L2 정규화는 원과 타원이 만나는 점이 많아져서 비교적 쉽게 연산되어 계산 효율 확보
        - 한 점에서 만나기 때문에 하나의 해답만 제공
    
    LinearRegression : 가장 기본적인 선형회귀 알고리즘을 사용하며, SGD가 아닌 최소자승법으로 계산한다
    Lasso : L1 손실을 활용한 라쏘 알고리즘을 사용한다
    Ridge : L2 손실을 활용한 리지 알고리즘을 사용한다
    SGDRegressor : 확률적 경사 하강법을 사용한 회귀 모델을 만든다

    회귀설계
        1. 데이터 확보
        2. 데이터 전처리
        3. 데이터 분류
        4. 데이터 학습
        5. 예측하기와 결과 분석
    
    데이터 확보
        - sklearn.datasets 라이브러리 load_boston 모듈을 사용하여 데이터를 추출
        - 딕셔너리 타입의 객체를 반환
        - data 키 값 추출
        - x와 y 각 데이터셋을 추출
        - y_data는 n*1의 형태로 반환
    
    데이터 전처리하기
        - 피쳐 스케일링 적용
    
    데이터 분류
        - 데이터를 훈련과 테스트 형태로 분류
    
    데이터 학습하기
        - 학습에 사용할 알고리즘 해당하는 모델의 클래스 호출
            * 각 클래스의 매개변수를 이해해야 함
    
    공통적으로 사용하는 매개변수 
        - fit_intercept : 절편을 사용할지 말지를 선택
        - normalize : 학습할 때 값들을 정규화할지 말지
        - copy_X : 학습 시 데이터를 복사한 후 학습을 할지 결정
        - n_jobs : 연산을 위해 몇 개의 CPU를 사용할지 결정
        - alpha : 라쏘 회귀, 리지 회귀, SGD에 있음. 페널티 값을 지정
    
    SDG의 매개변수
        - 직접 penalty 함수를 지정할 수 있는데, 람다 값을 alpha에 입력
        - max_iter : 최대 반복 횟수를 지정
        - tol : 더 이상 비용이 줄어들지 않을 때 반복이 멈추는 최솟값
        - etaO : 한 번에 실행되는 학습률
    
    사이킷런은 '적합-예측' 또는 '적합-변형'의 구조
        - 모델을 생성한 후 예측을 하거나 전처리 모델의 규칙을 세운 후 데이터 전처리를 적용하는 구조
    
    예측하기와 결과 분석
        - 만들어진 함수로 실제 예측을 한다
        - 사이킷런에서 지표들을 호출하여 성능을 비교
        - 필요에 따라 시각화 도구로 예측값과 실제값 비교

로지스틱 회귀
    분류 문제
        - 몇 가지 이산적 값 중 하나를 선택하는 모델. '분류 모델'이라고 부름
    
    로지스틱 회귀의 개념
        - 이진 분류 문제를 확률로 표현
        - 어떤 사건이 일어날 확률을 P(X)로 나타내고 일어나지 않을 확률을 1-P(X)로 나타냄
        - 오즈비(odds ratio) : 어떤 사건이 일어날 확률과 일어나지 않을 확률의 비율
    
    로짓(logit) 함수 : 오즈비에 상용로그를 붙인 수식
    로지스틱 함수 : 로짓 함수의 역함수