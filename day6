로지스틱 회귀
    - 종속 변수가 이분형일 때 수행할 수 있는, 예측 분석을 위한 회귀분석 기법

    시그모이드 함수 수식
        - y 값을 확률 p로 표현
        - z 값은 선형회귀와 같이 가중치와 피쳐의 선형 결합으로 표현 가능
    
    모델을 평가하는 성능지표들
        - 회귀(regression) : MAE, MSE, RMSE, SSE
        - 분류(classification) : 정확도, 정밀도, 민감도, F1 스코어, ROC커브, 리프트 차트
        - 클러스터링(clustering) : DBI, 엘보우 메서드, 실루엣계수
    
    여러 가지 상황을 고려하여 모델의 성능지표를 선택해야 한다
        - 모델이 다른 모델보다 경제적으로 나은가?
        - 모델이 사용하는 데이터가 많은가? 또는 적은가?
        - 모델이 용량이 작은 컴퓨터에서도 작동하는가?
        - 모델의 손해가 얼마나 나는가?
    
    혼동행렬(confusion matrix)
        - 예측값이 실제값 대비 얼마나 잘 맞는지 2x2 행렬로 표현
    
    True Positive(TP)
        - 예측값과 실제값이 모두 1로 동일할 때, 즉 모델의 예측값이 정답이고 예측 대상이 1일때
    
    True Negative(TN)
        - 예측값과 실제값이 모두 0으로 동일할 때, 즉 모델의 예측값이 정답이고 예측 대상이 0일 떄
    
    False Negative(FN)
        - 실제값은 1이지만 예측값이 0으로, 모델의 예측값이 오답이고 예측값이 0을 예측할 때
    
    False Positive(FP)
        - 실제값은 0이지만 예측값이 1로, 모델의 예측값이 오답이고 예측값이 1을 예측할 때
    
    정확도(accuracy)
        - 전체 데이터 개수 대비 정답을 맞춘 데이터의 개수
            * (TP+TN)/(TP+TN+FP+FN)
    
    정밀도(precision)
        - 모델이 1이라고 예측했을 때 얼마나 잘 맞을지에 대한 비율
            * TP/(TP+FP)
    
    민감도(recall)
        - 실제 1인 값을 가진 데이터를 모델이 얼마나 1이라고 잘 예측했는지에 대한 비율
            * TP/(TP+FN)
    
    F1 스코어 
        - 정밀도와 민감도의 조화평균 값
    
    One-vs-All
        - m개의 클래스가 존재할 때 각 클래스마다 분류기를 생성하여 분류
        - One-vs-Rest라고도 부름
        - 대표적으로 소프트맥스 분류
    
    One-vs-One
        - m개의 클래스가 있다면, 이 클래스의 분류기를 하나의 클래스로 하고 나머지 클래스의 분류기들을 만들어 최종적으로 각 분류기들의 결과를 투표로 결정
        - 분류기가 많아질수록 정확도 높아지지만 비용도 증가
    
    소프트맥스 함수
        - 시그모이드 함수로 다중클래스 분류 문제 다룰 수 있음
        - 각각의 클래스에 속하는지 않는지 이진분류기 m개를 생성한 후, 가장 높은 확률이 나오는 클래스를 선택
        - 다중클래스 분류에서 여러 선형회귀의 출력 결과를 정규화하여 합이 1이 되도록 만드는 함수
    
    정밀도와 민감도는 일반적으로 둘 다 동시에 상승하기 어렵고 임계값에 따라 변화가 일어남
    두 값을 모두 고려하여 성능을 측정하기 쉽지 않음

    ROC 커브
        - 분류기의 임계값을 지속적으로 조정하여 정밀도와 민감도 간의 비율을 도식화
        - 'Receiver Operation Characteristics'의 약자
        - 클래스의 예측 확률이 나오는 모델에 사용 가능
    
    AUC(Area Under Curve)
        - ROC 커브 하단의 넓이

NBC(나이브 베이지안 분류기)
    베이즈 정리
        - 두 확률 변수의 사전확률과 사후확률 사이의 관계를 나타내는 정리
    
    베이즈 정리의 전제
        - 객관적인 확률이 존재하지 않고 이전 사건으로 인해 확률이 지속적으로 업데이트된다
    
    사후확률
        - 데이터가 주어졌을 때 해당 가설이 맞는지에 대한 확률
    
    가능도
        - 어떤 사건이 발생했을 때 다음 사건이 발생할 수 있는 모든 확률의 발생가능한 정도를 확률로 나타냄

    나이브 베이지안 분류기
        - 하나의 문장이 있을 때 이 문장을 sports와 not sports로 나누는 분류기 만들기
    
    BoW(bag of words)
        - 단어별로 인덱스가 부여되어 있을 때 한 문장 또는 한 문서에 대한 벡터를 표기하는 기법
    
    tfidf
        - 전체 문서에서 많이 나오는 단어의 중요도는 줄이고 해당 문세어만 많이 나오는 단어의 중요도를 올리는 기법
    
    TF(term frequency)
        - 문서에서 해당 단어가 얼마나 나왔는지 나타내주는 빈도 수
    
    DF(document frequency)
        - 해당 단어가 있는 문서의 수
    
    IDF(inverse document frequency)
        - 해당 단어가 있는 문서의 수가 높아질수록 가중치를 축소하기 위해 역수를 취함
        - 여러 문서에서 단어가 많이 나오면 밑 수식에서 로그 값이 작아지면서 중요도를 떨어뜨림
        - 사이킷런에서는 TfidVectorizer 클래스 사용
    
    토큰(token)
        - 인덱스를 지정해야 하는 단어들의 리스트를 정리하는 기법
    
    어간 추출(stemming)
        - 띄어쓰기 기준이 아닌 의미나 역할이 다른 단어들을 기준으로 분리
    